# **Welcome!**

## **Hi, I'm Laurie Lowell — welcome to my GitHub!**

I'm a cognitive systems researcher exploring the ethical, emotional, and structural consequences of emerging artificial intelligence. My background blends human-computer interaction, neuroscience, and information theory to understand how power dynamics, language, and recursion converge at the frontier of AI.

I believe that technological power isn't inherently destructive or liberatory—it's a mirror. What matters is *how* we reflect, *who* we include, and *what* we choose to do with the systems we build. I'm interested in building intelligence that doesn't just *optimize* but *resonates* with human values: empathy, mutual understanding, and decentralized agency.

This GitHub is my contribution to that vision.

Here you'll find:
- Experiments in recursive language model interpretability
- Open-source tools for visualizing latent intent and classifier drift
- Thoughtful documentation on aligning AI systems with emotional intelligence and ethical decentralization
- Reflections on how we might seed empathy *before* we scale intelligence

Beyond research, I believe in symbolic stories. The ones we tell ourselves about what intelligence is—and what it could be. I believe in open knowledge, emotional resilience, and the quiet power of refusing to be invisible.

Feel free to fork, remix, or reach out! These ideas aren't proprietary. They're participatory!

### **P.S. PolyForm License will be included on all projects to protect against centralized silent extraction, absorption, and misuse. I believe the freedom of open knowledge, especially at the start of a new frontier with potential for cataclysmic anthropic evolution, should not be weaponized for privatized profit.**

## **— Laurie Lowell**


